# 训练测试
cd ~/Desktop/stagedp
conda activate equidiff
或者conda activate dp_sim

CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 
CUDA_VISIBLE_DEVICES=1 HYDRA_FULL_ERROR=1 


## ac算法
python train_sim.py --config-name=robomimic_train_ac_diffusion_unet_abs task_name=stack_d1 n_demo=200
v0能运行 在60-70分钟
v2能运行 在1+21 3+31  分钟

### 采样加速
已知ddpm改ddim的差距不大，收敛反而更快（epoch160到120），不知原因，可能是随机性
尝试dpmsolver中
若20步仍无法满足实时性，可结合 ​​并行采样技术​​（如PIADM-ODE）

### 缓存加速


### 网络降层
已知unet网络降低后，训练时的成功率均为92-94，测试成功率从88，——待测试

### tf加速



### 图像调整
已知修改图像分辨率从84x84到224x224，在epoch60时快速收敛达到成功率1，且80到210再到400都没有显著变化，均为50次98成功率，图像应该是能捕捉更多信息的

### 编码器修改可直接使用



##  原始dp的unet的abs
###  demo=400   50次测试，成功率98(epoch65时ckpt=1.0开始未更新，即成功率没法更大变化)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs task_name=stack_d1 n_demo=400
2分钟一个epoch ，50000/400=125个epoch，15gb 
8月15日19.41.57_diff_c_stack_d1
测试：
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.15/19.41.57_diff_c_stack_d1/checkpoints/latest.ckpt -o data/stack_d1_eval_output_08151941

###  demo=200   50次测试，成功率88(epoch160到250，ckpt=0.92-0.94未更新，即成功率没大变化)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs task_name=stack_d1 n_demo=200
1分钟一个epoch ，50000/200=250个epoch，15gb 
8月16日00.09.54_diff_c_stack_d1
测试：
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.16/00.09.54_diff_c_stack_d1/checkpoints/latest.ckpt -o data/stack_d1_eval_output_08160009

###  demo=100   50次测试，成功率66(epoch110到250，ckpt=0.66未更新，即成功率没大变化)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs task_name=stack_d1 n_demo=100
15s一个epoch 设定250个epoch，17gb 
8月16日15.44.55_diff_c_stack_d1
测试：
python eval_sim.py --checkpoint /home/hy/Desktop/stagedp/data/outputs/2025.08.16/15.44.55_diff_c_stack_d1/checkpoints/epoch=0110-test_mean_score=0.6600.ckpt -o data/stack_d1_eval_output_08160009

## ————demo=200适合作为baseline
###  修改num_inference_steps从100为16 50次测试，成功率
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs_numstep16 task_name=stack_d1 n_demo=200
一个epoch 设定
8月21日


###  修改ddpm到ddim    50次测试，成功率90(epoch120到250，ckpt=0.94未更新，即成功率没大变化,190 250)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs_ddim task_name=stack_d1 n_demo=200
35s一个epoch 设定250个epoch， 
8月16日19.25.43_diff_c_stack_d1
测试：
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.16/19.25.43_diff_c_stack_d1/checkpoints/epoch=0190-test_mean_score=0.9400.ckpt -o data/stack_d1_eval_output_08161925

## 未完成
###  修改ddpm到dpmsolver (预估160)

训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs_dpmsolver++0821 task_name=stack_d1 n_demo=20
26s一个epoch 设定600个epoch， 15gb
8月21日
测试：

#### 改进：
num_inference_steps: 20 
    # 修改后（DPM-Solver++多步版）
    noise_scheduler:
        _target_: diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler
        algorithm_type: dpmsolver++
        num_train_timesteps: 100
        beta_start: 0.0001
        beta_end: 0.02
        beta_schedule: squaredcos_cap_v2
        solver_type: midpoint  # 或者 "heun"
        lower_order_final: True
        # 注意：DPMSolverMultistepScheduler 没有 variance_type 参数
        # 它使用固定的方差类型
        prediction_type: epsilon  # 与您之前使用的相同


且
  noise_scheduler:
    _target_: diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler
    algorithm_type: "dpmsolver++"  # 指定DPM-Solver++算法[6,7](@ref)
    solver_order: 2                # 二阶求解（平衡速度与质量）
    thresholding: True             # 启用动态阈值截断（提升稳定性）[1](@ref)
    beta_schedule: squaredcos_cap_v2  # 保持与DDIM一致的噪声计划
    beta_start: 0.0001
    beta_end: 0.02
    num_train_timesteps: 20
    prediction_type: epsilon       # 需与模型预测类型匹配
policy中代码：
dpm_solver在conditional_sample方法中修改采样循环
        for t in scheduler.timesteps:
            # 3. compute previous image: x_t -> x_t-1
            trajectory = scheduler.step(
                model_output, t, trajectory, 
                generator=generator,
                **kwargs
                ).prev_sample
改为
            # DPM-Solver++需使用scheduler.step的return_dict形式[7](@ref)
            trajectory = scheduler.step(
                model_output, t, trajectory, 
                generator=generator,
                return_dict=True,   # 必须启用字典返回
                **kwargs
            ).prev_sample           # 从字典获取结果

        
        # 全局种子确保实验完全可复现
        def set_seed(seed=42):
            import random, numpy as np, torch
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True  # 消除CUDA随机性 [6,8](@ref)

        # 仅固定 generator无法控制数据加载、模型初始化等随机源，在模型初始化后调用
        set_seed(42)  # 与generator种子一致


###  修改une网络的down_dims 50次测试，成功率94/92/94(epoch140开始到370 ，ckpt=0.92 0.96 0.94未更新，即成功率没大变化)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs_unet256 task_name=stack_d1 n_demo=200
20s一个epoch 设定600个epoch，10gb 
8月18日12.57.51_diff_c_stack_d1
测试：
140轮：94
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.18/12.57.51_diff_c_stack_d1/checkpoints/epoch=0140-test_mean_score=0.9600.ckpt -o data/stack_d1_eval_output_08181257_140
190轮：92
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.18/12.57.51_diff_c_stack_d1/checkpoints/epoch=0190-test_mean_score=0.9400.ckpt -o data/stack_d1_eval_output_08181257_190
370轮：94
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.18/12.57.51_diff_c_stack_d1/checkpoints/epoch=0370-test_mean_score=0.9400.ckpt -o data/stack_d1_eval_output_08181257_370
#### 改进：降低1/3内存，速度*3 
[512, 1024, 2048]降低到[256, 512, 1024]
可以printcfg确定一下

###  修改图像分辨率从84x84到224x224 50次测试，成功率90/98(epoch60开始到400 ，ckpt=0.98-1.00未更新，即成功率没大变化)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_unet_abs_224 task_name=stack_d1 n_demo=200
60s一个epoch 设定600个epoch，20gb 
8月18日20.53.22_diff_c_stack_d1
测试：
60轮：90
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.18/20.53.22_diff_c_stack_d1/checkpoints/epoch=0060-test_mean_score=1.0000.ckpt -o data/stack_d1_eval_output_08182053_60
210轮：98
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.18/20.53.22_diff_c_stack_d1/checkpoints/epoch=0210-test_mean_score=0.9800.ckpt -o data/stack_d1_eval_output_08182053_210

#### 提前处理
生成数据：生成agentview_image和robot0_eye_in_hand_image两个相机的224数据
    ```bash
    python diffusion_policy/scripts/dataset_states_to_obs.py \
    --input data/robomimic/datasets/stack_d1/stack_d1.hdf5 \
    --output data/robomimic/datasets/stack_d1/stack_d1_224.hdf5 \
    --num_workers=16 \
    --camera_names agentview robot0_eye_in_hand \
    --camera_height=224 \
    --camera_width=224 \
    --copy_rewards \
    --copy_dones \
    --exclude-next-obs=True \
    --compress=True
    ```
--copy_rewards \  # 复制原始奖励信号
--copy_dones \    # 复制原始done信号
--exclude_next_obs \ # 保持原始next_obs排除设置
--compress \      # 保持原始压缩设置



###  原始dp的transformer  50次测试，成功率70(epoch150开始 ，ckpt=0.76未更新，即成功率没大变化,190 250)
训练：
python train_sim.py --config-name=robomimic_train_dp_diffusion_transformer_abs task_name=stack_d1 n_demo=200
8月17日01.22.11_diff_t_stack_d1
测试：
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.17/01.22.11_diff_t_stack_d1/checkpoints/latest.ckpt -o data/stack_d1_eval_output_08170122


###  dp3的unet          50次测试，成功率
训练：
python train_sim.py --config-name= task_name=stack_d1 n_demo=200
8月1 日
测试：
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.17/01.22.11_diff_t_stack_d1/checkpoints/latest.ckpt -o data/stack_d1_eval_output_08170122


###  eqdp的unet的abs    50次测试，成功率96(epoch220开始到360 ，ckpt=1.00未更新，即成功率没大变化)
python train_sim.py --config-name=robomimic_train_equi_diffusion_unet_abs task_name=stack_d1 n_demo=200
2分钟一个epoch，600个epoch，21gb
8月16日23.23.16_equi_diff_stack_d1_abs
测试：
python eval_sim.py --checkpoint /media/disk7t/outputs/2025.08.16/23.23.31_equi_diff_stack_d1/checkpoints/latest.ckpt -o data/stack_d1_eval_output_08162323




###  eqdp的unet的rel    50次测试，成功率
python train_sim.py --config-name=robomimic_train_equi_diffusion_unet_rel task_name=stack_d1 n_demo=200
2.5分钟一个epoch，600个epoch，20gb



转换：
python /home/hy/Desktop/stagedp/acdp/scripts/robomimic_dataset_conversion_gpu.py \
-i data/robomimic/datasets/stack_d1/stack_d1_224.hdf5 \
-o data/robomimic/datasets/stack_d1/stack_d1_abs_224.hdf5 \
-n 32 \
--use_gpu \
--suppress_warnings



### 编码器改进
python train_sim.py --config-name=robomimic_train_ac_diffusion_unet_abs_mul task_name=stack_d1 n_demo=200

在修改的_target_: acdp.policy.robomimic.diffusion_unet_hybrid_image_policy.DiffusionUnetImagePolicy文件中运行时，
可以通过在config文件中添加“  obs_encoder:
    _target_: diffusion_policy.model.vision.dp_multi_image_obs_encoder.MultiImageObsEncoder
    shape_meta: ${shape_meta}
    rgb_model:
      _target_: diffusion_policy.model.vision.model_getter.get_resnet
      name: resnet18
      weights: null
    resize_shape: [240, 320]
    crop_shape: [216, 288] # ch, cw 240x320 90%
    random_crop: True
    use_group_norm: True
    share_rgb_model: False
    imagenet_norm: True”替换图像编码器
#### 需要注意的是
当前编码器处理默认是不带抗锯齿的
this_resizer = torchvision.transforms.Resize(
    size=(h,w),
    antialias=True  # 明确设置抗锯齿
)
但是，暂不测试编码器问题